import numpy as np
import lda 
import lda.datasets
import json

f = open("dataMD5","r")
data = f.readlines()
data = [x.strip() for x in data]
md5data = []
for i in data:
    md5data.append(i)
f.close()

f = open("maldozer_label","r")
data = f.readlines()
data = [x.strip() for x in data]
md5title = []
for i in data:
    md5title.append(i)
f.close()


#print(md5data)


X = lda.datasets.load_reuters()
#print(X)

vocab = md5title
#print(len(vocab))
titles = md5data


#print(X.shape)
#print(titles)
X.sum()

model=lda.LDA(n_topics=20, n_iter=1500, random_state=1)
model.fit(X)

topic_word = model.topic_word_
n_top_words = 8

for i, topic_dist in enumerate(topic_word):
    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]
    print('Topic {}: {}'.format(i,' '.join(topic_words)))